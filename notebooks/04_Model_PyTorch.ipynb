{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b684e130",
   "metadata": {},
   "source": [
    "# ðŸ§¬ PyTorch Skin Condition Classification (ISIC 2019) - Code Explanation Notebook\n",
    "\n",
    "This notebook provides a **detailed explanation** of the PyTorch-based skin condition classification pipeline using the **ISIC 2019 dataset**. Instead of training a model, we'll focus on understanding *what each component does*, *why architectural and optimization choices were made*, and *how the code implements best practices* for medical image classification.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "1. [Architecture Overview](#1-architecture-overview)\n",
    "2. [Dataset & Data Loading](#2-dataset--data-loading)\n",
    "3. [Model Architecture](#3-model-architecture)\n",
    "4. [Training Strategy](#4-training-strategy)\n",
    "5. [Optimization Techniques](#5-optimization-techniques)\n",
    "6. [Evaluation & Visualization](#6-evaluation--visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a25a76",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 1. Architecture Overview\n",
    "\n",
    "Let's first examine the overall structure of the PyTorch implementation:\n",
    "\n",
    "```python\n",
    "# Key Components:\n",
    "# 1. SkinConditionDataset - Custom PyTorch Dataset for medical images\n",
    "# 2. EfficientNetB0PyTorch - Modified EfficientNet-B0 with custom head\n",
    "# 3. SkinConditionTrainer - Main training orchestration class\n",
    "# 4. Specialized components: FocalLoss, AddGaussianNoise, Gradual Unfreezing\n",
    "```\n",
    "\n",
    "### Why PyTorch for Medical Imaging?\n",
    "\n",
    "- **Dynamic Computation Graphs**: Flexible for experimentation\n",
    "- **Fine-grained Control**: Better for custom architectures and training loops\n",
    "- **Research-Friendly**: Widely used in academic medical imaging research\n",
    "- **GPU Optimization**: Excellent CUDA integration for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2131783",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2. Dataset & Data Loading\n",
    "\n",
    "### 2.1 Custom Dataset Class\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "class SkinConditionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Pre-filter valid files during initialization\n",
    "        self.valid_indices = []\n",
    "        \n",
    "        print(\"Verifying image files...\")\n",
    "        for idx in tqdm(range(len(self.df)), desc=\"Checking files\"):\n",
    "            image_path = self.df.iloc[idx]['filepath']\n",
    "            if os.path.exists(image_path):\n",
    "                self.valid_indices.append(idx)\n",
    "            else:\n",
    "                print(f\"Warning: File not found - {image_path}\")\n",
    "```\n",
    "\n",
    "**Key Design Choices:**\n",
    "\n",
    "1. **Pre-filtering**: Validates all files during initialization to avoid runtime errors\n",
    "2. **Memory Efficiency**: Stores only valid indices, not entire dataset in memory\n",
    "3. **Error Handling**: Gracefully handles missing files and returns dummy tensors\n",
    "4. **Pre-resizing**: Images resized to 224Ã—224 during loading to reduce transform overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b9a18",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Data Transforms\n",
    "\n",
    "```python\n",
    "import torch\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0., std=0.02):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor) * self.std\n",
    "```\n",
    "**Augmentation Strategy:**\n",
    "```python\n",
    "from torchvision import transforms\n",
    "# Training transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=3),          # Mild rotation (Â±3Â°)\n",
    "    transforms.RandomResizedCrop(224, scale=(0.92, 1.0)),  # Zoom variation\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, \n",
    "                         saturation=0.05, hue=0.05),  # Color variations\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet statistics\n",
    "                       std=[0.229, 0.224, 0.225]),\n",
    "    AddGaussianNoise(std=0.02)                     # Sensor noise simulation\n",
    "])\n",
    "```\n",
    "**Why These Specific Augmentations?**\n",
    "\n",
    "- **Mild Augmentations**: Medical images require preservation of diagnostic features\n",
    "- **ImageNet Normalization**: Pretrained weights expect ImageNet statistics\n",
    "- **Gaussian Noise**: Models real-world sensor noise and compression artifacts\n",
    "- **Color Jitter**: Accounts for varying lighting conditions and skin tones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26298cda",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 DataLoader Configuration\n",
    "```python\n",
    "num_workers = min(6, os.cpu_count())\n",
    "persistent_workers = True\n",
    "prefetch_factor = 3\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    drop_last=True,\n",
    "    pin_memory_device=str(device) if device.type == 'cuda' else ''\n",
    ")\n",
    "```\n",
    "**Optimization Decisions:**\n",
    "\n",
    "1. **`persistent_workers=True`**: Keeps worker processes alive between epochs\n",
    "2. **`prefetch_factor=3`**: Preloads batches to reduce GPU idle time\n",
    "3. **`pin_memory=True`**: Enables faster GPU data transfer\n",
    "4. **`drop_last=True`**: Ensures consistent batch sizes for batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759699a0",
   "metadata": {},
   "source": [
    "\n",
    "--- \n",
    "## 3. Model Architecture\n",
    "\n",
    "### 3.1 Modified EfficientNet-B0\n",
    "\n",
    "```python\n",
    "class EfficientNetB0PyTorch(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Load pretrained EfficientNet-B0\n",
    "        self.base_model = models.efficientnet_b0(pretrained=pretrained)\n",
    "        \n",
    "        # Initially freeze ALL layers\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Modify classifier head\n",
    "        in_features = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Always keep classifier trainable\n",
    "        for param in self.base_model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "```\n",
    "\n",
    "**Architectural Choices:**\n",
    "\n",
    "1. **Transfer Learning**: Uses pretrained EfficientNet-B0 (ImageNet weights)\n",
    "2. **Initial Freezing**: All backbone layers frozen at start (prevents catastrophic forgetting)\n",
    "3. **Enhanced Classifier Head**:\n",
    "   - Two fully-connected layers (256 â†’ num_classes)\n",
    "   - Batch normalization for stability\n",
    "   - High dropout (0.5) for regularization\n",
    "   - ReLU activation for non-linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367094b",
   "metadata": {},
   "source": [
    "### 3.2 Focal Loss for Class Imbalance\n",
    "\n",
    "```python\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = nn.functional.cross_entropy(\n",
    "            logits, targets, weight=self.alpha, reduction='none'\n",
    "        )\n",
    "        pt = torch.exp(-ce)\n",
    "        return ((1 - pt) ** self.gamma * ce).mean()\n",
    "```\n",
    "\n",
    "**Why Focal Loss?**\n",
    "\n",
    "- **Class Imbalance**: ISIC dataset has highly imbalanced classes (NV â‰« DF, VASC)\n",
    "- **Hard Example Focus**: Down-weights easy examples, focuses on hard misclassifications\n",
    "- **Adaptive Weighting**: Î³=2.0 provides moderate focusing (common in medical tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61be07",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 4. Training Strategy\n",
    "\n",
    "### 4.1 Gradual Unfreezing Schedule\n",
    "\n",
    "```python\n",
    "class SkinConditionTrainer:\n",
    "    def __init__(self, config):\n",
    "        # Gradual unfreezing configuration\n",
    "        self.unfreezing_schedule = [\n",
    "            (0, 7, 1.0),    # Start: freeze most blocks (7/8)\n",
    "            (20, 5, 0.5),   # Epoch 20: unfreeze some layers\n",
    "            (40, 3, 0.2),   # Epoch 40: unfreeze more\n",
    "            (60, 1, 0.1),   # Epoch 60: almost all unfrozen\n",
    "            (80, 0, 0.05),  # Epoch 80: all layers trainable\n",
    "        ]\n",
    "```\n",
    "\n",
    "**Gradual Unfreezing Logic:**\n",
    "\n",
    "1. **Stage 1 (Epochs 0-19)**: Only classifier trainable\n",
    "2. **Stage 2 (Epochs 20-39)**: Unfreeze last 3 blocks, lower learning rate\n",
    "3. **Stage 3 (Epochs 40-59)**: Unfreeze more layers, further reduced LR\n",
    "4. **Stage 4 (Epochs 60-79)**: Most layers unfrozen\n",
    "5. **Stage 5 (Epochs 80+)**: All layers trainable at very low LR\n",
    "\n",
    "**Why Gradual Unfreezing?**\n",
    "\n",
    "- **Stable Training**: Prevents disruption of pretrained features\n",
    "- **Progressive Specialization**: Allows network to adapt slowly to medical domain\n",
    "- **Learning Rate Annealing**: Lower LRs for deeper layers (empirical best practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04ae84",
   "metadata": {},
   "source": [
    "### 4.2 Optimizer Configuration\n",
    "\n",
    "```python\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],           # 5e-5\n",
    "    weight_decay=config['weight_decay']  # 1e-5\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',                # Monitor validation accuracy\n",
    "    factor=0.5,                # Halve LR when plateau\n",
    "    patience=5,                # Wait 5 epochs\n",
    "    min_lr=1e-6,               # Minimum learning rate\n",
    "    verbose=True\n",
    ")\n",
    "```\n",
    "\n",
    "**Optimizer Selection Rationale:**\n",
    "\n",
    "- **AdamW**: Better generalization than Adam (decoupled weight decay)\n",
    "- **Learning Rate**: Small initial LR (5e-5) for fine-tuning\n",
    "- **Weight Decay**: Moderate regularization (1e-5)\n",
    "- **ReduceLROnPlateau**: Adaptive learning rate based on validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbec092",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 5. Optimization Techniques\n",
    "\n",
    "### 5.1 Mixed Precision Training\n",
    "\n",
    "```python\n",
    "self.scaler = GradScaler()  # For mixed precision\n",
    "\n",
    "# In training loop:\n",
    "with autocast():  # Mixed precision context\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "self.scaler.scale(loss).backward()\n",
    "self.scaler.step(optimizer)\n",
    "self.scaler.update()\n",
    "```\n",
    "\n",
    "**Benefits of Mixed Precision:**\n",
    "\n",
    "- **Memory Efficiency**: FP16 uses half the memory of FP32\n",
    "- **Speed**: Faster computation on modern GPUs (Tensor Cores)\n",
    "- **Same Accuracy**: Gradient scaling maintains training stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b2dd9",
   "metadata": {},
   "source": [
    "### 5.2 GPU Optimization Settings\n",
    "\n",
    "```python\n",
    "# Enable PyTorch optimizations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n",
    "    torch.set_float32_matmul_precision('high')  # For Ampere+ GPUs\n",
    "\n",
    "# DataLoader optimizations\n",
    "pin_memory=True\n",
    "persistent_workers=True\n",
    "prefetch_factor=3\n",
    "```\n",
    "\n",
    "**Performance Optimizations:**\n",
    "\n",
    "1. **cuDNN Benchmarking**: Auto-tunes for optimal convolution algorithms\n",
    "2. **Tensor Core Utilization**: High precision setting for Ampere GPUs\n",
    "3. **Data Loading Pipeline**: Overlapping data loading with computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c08485",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 6. Evaluation & Visualization\n",
    "\n",
    "### 6.1 Comprehensive Metrics Tracking\n",
    "\n",
    "```python\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [],\n",
    "    'frozen_layers': [], 'lr_multiplier': []  # Tracks training dynamics\n",
    "}\n",
    "```\n",
    "\n",
    "**Monitoring Strategy:**\n",
    "\n",
    "- **Training Metrics**: Loss and accuracy per epoch\n",
    "- **Validation Metrics**: Early stopping based on validation accuracy\n",
    "- **Training Dynamics**: Frozen layers count and LR multiplier over time\n",
    "- **GPU Utilization**: Memory usage monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66918228",
   "metadata": {},
   "source": [
    "### 6.2 Visualization Functions\n",
    "\n",
    "```python\n",
    "def plot_results(self, history, y_true, y_pred, class_names):\n",
    "    # 1. Training curves (accuracy & loss)\n",
    "    # 2. Unfreezing progression\n",
    "    # 3. Learning rate schedule\n",
    "    # 4. Confusion matrix\n",
    "    # 5. Classification report\n",
    "```\n",
    "\n",
    "**Visualization Components:**\n",
    "\n",
    "1. **Training Curves**: Monitor overfitting and convergence\n",
    "2. **Unfreezing Timeline**: Visualize gradual unfreezing strategy\n",
    "3. **Confusion Matrix**: Per-class performance analysis\n",
    "4. **Classification Report**: Precision, recall, F1-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c2d61",
   "metadata": {},
   "source": [
    "### 6.3 Model Saving Strategy\n",
    "\n",
    "```python\n",
    "# Save checkpoints\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'val_acc': val_acc,\n",
    "    'frozen_layers': current_freeze,\n",
    "    'config': config\n",
    "}, 'best_model_gradual.pth')\n",
    "\n",
    "# Save training history\n",
    "joblib.dump(history, 'pytorch_history_gradual.joblib')\n",
    "```\n",
    "\n",
    "**Checkpoint Contents:**\n",
    "\n",
    "1. **Model Weights**: For inference or resuming training\n",
    "2. **Optimizer State**: Maintains momentum and adaptive learning rates\n",
    "3. **Training Metadata**: Epoch, validation accuracy, frozen layer count\n",
    "4. **Configuration**: Reproducibility of training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94425f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### Architectural Decisions:\n",
    "- **EfficientNet-B0**: Optimal accuracy/efficiency trade-off\n",
    "- **Custom Head**: Enhanced capacity for medical domain adaptation\n",
    "- **Gradual Unfreezing**: Stable transfer learning strategy\n",
    "\n",
    "### Optimization Choices:\n",
    "- **Mixed Precision**: Memory and speed benefits\n",
    "- **Focal Loss**: Handles class imbalance effectively\n",
    "- **AdamW Optimizer**: Better generalization than standard Adam\n",
    "\n",
    "### Medical Imaging Considerations:\n",
    "- **Mild Augmentations**: Preserve diagnostic features\n",
    "- **Class Weights**: Address dataset imbalance\n",
    "- **Careful Normalization**: Use ImageNet statistics for pretrained models\n",
    "\n",
    "### PyTorch-Specific Best Practices:\n",
    "- **Custom Dataset Class**: Efficient data loading with pre-filtering\n",
    "- **DataLoader Optimizations**: `pin_memory`, `persistent_workers`, `prefetch_factor`\n",
    "- **Modular Design**: Separated trainer, model, dataset for maintainability\n",
    "\n",
    "This PyTorch implementation demonstrates a **production-ready, research-informed approach** to medical image classification, balancing performance, accuracy, and practical considerations for real-world deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
