{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930fc896",
   "metadata": {},
   "source": [
    "# üìì 02 ‚Äì Train / Validation / Test Split \n",
    "\n",
    "This notebook performs a **stratified split** of the ISIC 2019 dataset into\n",
    "training, validation, and test sets.\n",
    "\n",
    "Key objectives:\n",
    "- Prevent data leakage\n",
    "- Preserve class distributions across splits\n",
    "- Organize images into a folder structure compatible with deep learning frameworks\n",
    "- Generate CSV metadata files for reproducible experiments\n",
    "\n",
    "This split is reused across both TensorFlow and PyTorch models to ensure fair comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ca4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add project root to Python path\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from data_cleaning.paths import PROCESSED_DATA, WORKED_IMGS, DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ef6df",
   "metadata": {},
   "source": [
    "## üìÑ Load Processed Metadata\n",
    "\n",
    "We load the cleaned and preprocessed ISIC 2019 metadata generated during\n",
    "the data preparation stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82b1ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AK</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "      <th>SCC</th>\n",
       "      <th>UNK</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_idx</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "      <td>c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "      <td>c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "      <td>c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MEL</td>\n",
       "      <td>0</td>\n",
       "      <td>c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK label_name  \\\n",
       "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0         NV   \n",
       "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0         NV   \n",
       "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0        MEL   \n",
       "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0         NV   \n",
       "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0        MEL   \n",
       "\n",
       "   label_idx                                           filepath  \n",
       "0          1  c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...  \n",
       "1          1  c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...  \n",
       "2          0  c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...  \n",
       "3          1  c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...  \n",
       "4          0  c:\\Users\\hasee\\Documents\\Python_works\\Image_cl...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PROCESSED_DATA, \"ISIC_2019_Training_GroundTruth.csv\"))\n",
    "\n",
    "# Absolute path to processed images\n",
    "df[\"filepath\"] = df[\"image\"].apply(\n",
    "    lambda x: os.path.join(WORKED_IMGS, f\"{x}.jpg\")\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c757224c",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Stratified Dataset Split\n",
    "\n",
    "We split the dataset as follows:\n",
    "- **70% Training**\n",
    "- **15% Validation**\n",
    "- **15% Test**\n",
    "\n",
    "Stratification is applied on `label_idx` to preserve class distribution,\n",
    "which is critical in imbalanced medical datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91188413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 17731\n",
      "Validation: 3800\n",
      "Test: 3800\n"
     ]
    }
   ],
   "source": [
    "# Train vs temp (70 / 30)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    stratify=df[\"label_idx\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Validation vs Test (15 / 15)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label_idx\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Validation:\", len(val_df))\n",
    "print(\"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817b884",
   "metadata": {},
   "source": [
    "## üìÅ Organizing Files on Disk\n",
    "\n",
    "Images are copied into the following directory structure:\n",
    "\n",
    "```\n",
    "DATA/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ MEL/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NV/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ MEL/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "    ‚îú‚îÄ‚îÄ MEL/\n",
    "    ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "This structure is compatible with both TensorFlow and PyTorch dataloaders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa686ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17731/17731 [00:32<00:00, 549.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3800/3800 [00:06<00:00, 548.80it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3800/3800 [00:06<00:00, 558.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def move_files(df: pd.DataFrame, split_name: str):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        label = row[\"label_name\"]\n",
    "        src = row[\"filepath\"]\n",
    "        dst = os.path.join(DATA, split_name, label)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "# move_files(train_df, \"train\") # to move files accordingly\n",
    "# move_files(val_df, \"val\")     # to move files accordingly\n",
    "# move_files(test_df, \"test\")   # to move files accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e319ef72",
   "metadata": {},
   "source": [
    "## üíæ Save Split Metadata\n",
    "\n",
    "CSV files are saved for each split to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e81bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=[\"filepath\"]).to_csv(\n",
    "    os.path.join(DATA, \"train\", \"split_train.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "val_df.drop(columns=[\"filepath\"]).to_csv(\n",
    "    os.path.join(DATA, \"val\", \"split_val.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "test_df.drop(columns=[\"filepath\"]).to_csv(\n",
    "    os.path.join(DATA, \"test\", \"split_test.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4630b",
   "metadata": {},
   "source": [
    "## üîç File Integrity Check\n",
    "\n",
    "We verify that all images referenced in the CSV files exist on disk.\n",
    "Missing files are reported and filtered out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa79446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train SET\n",
      "Total: 17731\n",
      "Found: 17731\n",
      "Missing: 0\n",
      "\n",
      "Val SET\n",
      "Total: 3800\n",
      "Found: 3800\n",
      "Missing: 0\n",
      "\n",
      "Test SET\n",
      "Total: 3800\n",
      "Found: 3800\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "def check_files(split_name, df):\n",
    "    print(f\"\\n{split_name} SET\")\n",
    "    df[\"filepath\"] = df.apply(\n",
    "        lambda row: os.path.join(DATA, split_name.lower(), row[\"label_name\"], f\"{row['image']}.jpg\"),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df[\"exists\"] = df[\"filepath\"].apply(os.path.exists)\n",
    "    print(\"Total:\", len(df))\n",
    "    print(\"Found:\", df[\"exists\"].sum())\n",
    "    print(\"Missing:\", len(df) - df[\"exists\"].sum())\n",
    "    \n",
    "    return df[df[\"exists\"]].copy()\n",
    "\n",
    "train_df = check_files(\"Train\", train_df)\n",
    "val_df   = check_files(\"Val\", val_df)\n",
    "test_df  = check_files(\"Test\", test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fed0f6",
   "metadata": {},
   "source": [
    "## üìä Final Dataset Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16e01d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 25331\n",
      "Train: 17731 (70.0%)\n",
      "Validation: 3800 (15.0%)\n",
      "Test: 3800 (15.0%)\n"
     ]
    }
   ],
   "source": [
    "total = len(train_df) + len(val_df) + len(test_df)\n",
    "\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Train: {len(train_df)} ({len(train_df)/total*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val_df)} ({len(val_df)/total*100:.1f}%)\")\n",
    "print(f\"Test: {len(test_df)} ({len(test_df)/total*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22de1fe",
   "metadata": {},
   "source": [
    "## üß™ Class Distribution per Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c685aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train distribution:\n",
      "NV: 9012 (50.8%)\n",
      "MEL: 3165 (17.9%)\n",
      "BCC: 2326 (13.1%)\n",
      "BKL: 1837 (10.4%)\n",
      "AK: 607 (3.4%)\n",
      "SCC: 440 (2.5%)\n",
      "VASC: 177 (1.0%)\n",
      "DF: 167 (0.9%)\n",
      "\n",
      "Validation distribution:\n",
      "NV: 1932 (50.8%)\n",
      "MEL: 678 (17.8%)\n",
      "BCC: 498 (13.1%)\n",
      "BKL: 394 (10.4%)\n",
      "AK: 130 (3.4%)\n",
      "SCC: 94 (2.5%)\n",
      "VASC: 38 (1.0%)\n",
      "DF: 36 (0.9%)\n",
      "\n",
      "Test distribution:\n",
      "NV: 1931 (50.8%)\n",
      "MEL: 679 (17.9%)\n",
      "BCC: 499 (13.1%)\n",
      "BKL: 393 (10.3%)\n",
      "AK: 130 (3.4%)\n",
      "SCC: 94 (2.5%)\n",
      "VASC: 38 (1.0%)\n",
      "DF: 36 (0.9%)\n"
     ]
    }
   ],
   "source": [
    "for name, split_df in [(\"Train\", train_df), (\"Validation\", val_df), (\"Test\", test_df)]:\n",
    "    print(f\"\\n{name} distribution:\")\n",
    "    counts = split_df[\"label_name\"].value_counts()\n",
    "    for label, count in counts.items():\n",
    "        print(f\"{label}: {count} ({count/len(split_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd3f23",
   "metadata": {},
   "source": [
    "### ‚úÖ Outcome\n",
    "\n",
    "- Dataset successfully split with no data leakage\n",
    "- Class distributions preserved across splits\n",
    "- Images organized for deep learning pipelines\n",
    "- Metadata saved for reproducibility\n",
    "\n",
    "This split will be reused for:\n",
    "- TensorFlow training\n",
    "- PyTorch training\n",
    "- Model comparison and evaluation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
